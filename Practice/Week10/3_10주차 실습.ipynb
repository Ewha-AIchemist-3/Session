{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guideline\n",
    "\\# TODO : ~~\n",
    "\n",
    "목표에 맞게 코드를 작성하면 됩니다!\n",
    "\n",
    "교재의 코드 참고해도 좋아요~\n",
    "\n",
    "KoNLPy의 Okt를 사용하기 때문에 KoNLPy가 설치되어있어야 합니다!\n",
    "\n",
    "이 노트북에서는 <b>'과제명' 피처만 사용하여 학습</b>시킵니다! 다른 피처도 사용하면 더 성능이 좋아질 가능성이 높겠죠? 나중에 시도해보시는 것 추천드려요b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. 데이터 및 라이브러리 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : 데이터 import (train, test, 자신의 데이터셋 위치 고려하여 작성!)\n",
    "\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. 데이터 EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구조 파악\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화\n",
    "#### 레이블 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 분포 확인\n",
    "label_counts = train['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# 레이블 분포 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "label_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% 이상을 0 레이블이 차지합니다.\n",
    "\n",
    "불균형한 레이블 분포이고, 데이터 건수가 너무 많기 때문에 언더 샘플링, SMOTE 오버샘플링을 수행할 예정입니다.\n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텍스트 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트분석에서 <b>텍스트의 길이 분석이 도움되는 점</b>\n",
    "1. 전처리 결정\n",
    "- 이상치 제거\n",
    "- 데이터 불균형 탐지 및 처리\n",
    "2. 모델 선택 및 설정\n",
    "- 텍스트 길이 따른 적절한 모델 선택 <br>\n",
    "긴 텍스트를 처리해야 하는 경우, 단순한 모델보다 LSTM이나 Transformer와 같은 더 복잡한 모델이 필요할 수 있다.\n",
    "3. 패딩 전략 수립 <br>\n",
    "시퀀스 모델에서 입력 길이를 맞추기 위해 패딩을 사용할 때, 적절한 최대 시퀀스 길이를 설정하는 데 도움이 된다.<br><br>\n",
    "등등...\n",
    "<br>\n",
    "<b>하지만 이 노트북에서는 단순한 전처리만 할 예정입니다. 참고만 해주세요!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=train['과제명'].astype(str).apply(len)\n",
    "plt.hist(length, bins=50, alpha=0.5, color='r', label='word') # 히스토그램 그리기 (bins = 구간 개수, label = 해당 그래프 데이터 레이블)\n",
    "plt.title('histogram of length of task_name')\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.boxplot(length, labels=['counts'], showmeans=True)\n",
    "print('과제명 길이 최댓값: {}'.format(np.max(length)))\n",
    "print('과제명 길이 최솟값: {}'.format(np.min(length)))\n",
    "print('과제명 길이 평균값: {}'.format(np.mean(length)))\n",
    "print('과제명 길이 중간값: {}'.format(np.median(length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. 데이터 전처리**\n",
    "\n",
    "'과제명'만 학습에 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['과제명']]\n",
    "y_train = train[['label']]\n",
    "test = test[['과제명']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 정의\n",
    "def preprocessing(text, okt, remove_stopwords=False, stop_words=[]):\n",
    "    # TODO : 한글 및 공백만 남기고 제거하기 (힌트: OO.OOO(r'한글 및 공백 제외 문자', '', OOOO) / 교재 521p 참고)\n",
    "    text = \n",
    "    # TODO : okt로 형태소 분석 (0000, stem = True)\n",
    "    word_text = \n",
    "    # stop word 제거\n",
    "    if remove_stopwords:\n",
    "        word_review=[token for token in word_text if not token in stop_words]\n",
    "    return word_review\n",
    "\n",
    "# stop word(불용어) 리스트\n",
    "stop_words=['은','는','이','가', '하','아','것','들','의','있','되','수','보','주','등','한']\n",
    "\n",
    "# TODO : Okt 객체 생성\n",
    "okt = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 및 테스트 데이터 전처리\n",
    "clean_train_text = []\n",
    "clean_test_text = []\n",
    "\n",
    "# 데이터 건수가 많아 오래걸립니다.\n",
    "for text in tqdm.tqdm(X_train['과제명']):\n",
    "    try:\n",
    "        clean_train_text.append(preprocessing(text, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    except:\n",
    "        clean_train_text.append([])\n",
    "\n",
    "for text in tqdm.tqdm(test['과제명']):\n",
    "    if isinstance(text, str):\n",
    "        clean_test_text.append(preprocessing(text, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else:\n",
    "        clean_test_text.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 피처 벡터화\n",
    "\n",
    "# 1. CountVectorizer, TfidfVectorizer 모듈 임포트\n",
    "\n",
    "\n",
    "# 2. CountVectorizer 객체 생성 / 이름: cnt_vect, (파라미터: tokenizer = lamda x : x, lowercase = False)\n",
    "# tokenizer 인자에는 list를 받아서 그대로 내보내는 함수를 넣어줍니다. 또한 소문자화를 하지 않도록 설정해야 에러가 나지 않습니다.\n",
    "\n",
    "# 학습 데이터 피처 벡터화 / 이름: cnt_train_features\n",
    "\n",
    "# 테스트 데이터 피처 벡터화 / 이름: cnt_tst_features (fit_transform / fit / transform 중 뭐가 맞을까요?)\n",
    "\n",
    "\n",
    "# 3. TfidfVectorizer 객체 생성 / 이름: tfidf_vect, (파라미터: tokenizer = lamda x : x, lowercase = False)\n",
    "\n",
    "# CountVectorizer처럼 학습, 테스트 데이터 피처 벡터화 / 이름: tfidf_train_features, tfidf_test_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간 상의 문제로 TF-IDF 벡터화한 데이터셋으로 계속 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언더 샘플링 및 SMOTE 오버 샘플링\n",
    "# *imbalanced-learn 파이썬 패키지가 설치되어 있어야 합니다. (분류 챕터 숙제하셨다면 설치완료!)\n",
    "# 설치: 아나콘다 프롬프트를 관리자 권한 실행 -> conda install -c conda-forge imbalanced-learn \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 언더 샘플링\n",
    "under_sampler = RandomUnderSampler(\n",
    "        sampling_strategy={0: 5000}, # 0 레이블을 5000개로 감소\n",
    "        random_state=42\n",
    "        )\n",
    "X_under, y_under = under_sampler.fit_resample(train_features_tfidf, y_train)\n",
    "\n",
    "# SMOTE 오버 샘플링\n",
    "smote = SMOTE(\n",
    "        sampling_strategy='not majority',  # 다수 클래스 제외한 나머지만 증가\n",
    "        random_state=42,\n",
    "        k_neighbors=5\n",
    "        )\n",
    "X_balanced, y_balanced = smote.fit_resample(X_under, y_under) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 학습 피처 데이터 세트\n",
    "X_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 학습 레이블 데이터 세트\n",
    "y_balanced.label.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. 모델링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 셋과 검증 데이터 셋으로 분리\n",
    "TEST_SIZE=0.2\n",
    "RANDOM_SEED=42\n",
    "\n",
    "# TODO: 빈칸 채우기!\n",
    "train_x, eval_x, train_y, eval_y=_____________(__________, __________, __________, __________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 랜덤포레스트로 모델링\n",
    "# 랜덤포레스트 모듈 임포트\n",
    "\n",
    "# RandomForestClassifier 모델 생성 (결정 트리 개수 100개, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# 학습 데이터로 모델 훈련\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 모델 검증 (빈칸 채우기)\n",
    "forest.score(_______, _______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. 예측 및 제출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 피처 벡터화한 테스트 데이터 사용해 랜덤포레스트 모델 예측, test_predictions에 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 샘플 제출용 데이터프레임에 예측 결과 업데이트 (빈칸 채우기)\n",
    "sample_submission['label'] = ________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출할 예측 결과 파일 생성!\n",
    "sample_submission.to_csv('submission0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "직접 사이트에 제출해보셔도 됩니다!\n",
    "\n",
    "점수는.. 기대 안하시는게.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
